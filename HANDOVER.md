# Clipping.AI - Project Handover Document

**Last Updated**: November 17, 2025
**Status**: Core MVP Functional - 8/14 Major Features Complete
**Demo Ready**: âœ… Yes

---

## Table of Contents
1. [Project Overview](#project-overview)
2. [What's Been Built](#whats-been-built)
3. [Getting Started](#getting-started)
4. [Architecture](#architecture)
5. [Key Files & Directories](#key-files--directories)
6. [Environment Variables](#environment-variables)
7. [Testing the Product](#testing-the-product)
8. [What's Next](#whats-next)
9. [Known Issues & Considerations](#known-issues--considerations)
10. [Common Commands](#common-commands)

---

## Project Overview

**Clipping.AI** is an AI-powered competitive intelligence platform that automatically generates premium business intelligence reports.

### The Value Proposition
- Users enter their email â†’ We detect their company
- They select report types (Competitor Intelligence, Market Trends, Media Monitoring)
- AI generates a **professional intelligence report** in ~2 minutes
- Users see the full report **BEFORE signing up** (show value first!)
- Beautiful editorial presentation drives conversions

### Tech Stack
- **Frontend**: React + TypeScript + Vite
- **Backend**: Express + TypeScript
- **Database**: Neon PostgreSQL (schema ready, not yet integrated)
- **AI Models**:
  - Claude Sonnet 4.5 (query planning, content analysis, synthesis)
  - gpt-image-1 (professional business illustrations)
  - Gemini Flash 1.5 (logo extraction from HTML)
- **Search**: Tavily AI (web search)
- **Monorepo**: pnpm workspaces

### Current State
âœ… **Fully functional end-to-end MVP** with real AI generation
ğŸš€ **Ready for demo/testing** with actual users
ğŸ“Š **8/14 major features complete**

---

## What's Been Built

### âœ… Completed Features

#### 1. **Landing Page** (`apps/web/src/pages/Landing.tsx`)
- Email capture with animated background
- "Intelligence Dashboard meets Editorial Magazine" design
- Redirects to onboarding with email parameter

#### 2. **Company Detection** (`apps/api/src/services/companyDetection.ts`)
- Extracts company from email domain
- Scrapes company website for info
- **Intelligent logo extraction** using Gemini Flash 1.5
- Fallback to manual input if detection fails

#### 3. **Onboarding Flow** (`apps/web/src/pages/Onboarding.tsx`)
- **9-step flow**: detecting â†’ verify â†’ suggestions â†’ **generating** â†’ questions â†’ signup â†’ complete
- Company verification with logo options
- Report type selection (3 types)
- **Key change**: Shows report BEFORE asking for signup

#### 4. **Report Generation Service** (`apps/api/src/services/reportGeneration.ts`)
**This is the heart of the product** - A sophisticated 7-step AI pipeline:

1. **Query Planning** (Claude): Generates 5-7 optimal search queries
2. **Web Search** (Tavily): Finds 30+ relevant articles
3. **Article Extraction** (Claude): Ranks and selects top 5
4. **Summarization** (Claude): Creates 300-500 word analyses
5. **Synthesis** (Claude): Generates compelling TL;DR
6. **Image Generation** (gpt-image-1): Creates custom illustrations
7. **Response**: Returns structured JSON

**Generation Time**: ~2 minutes
**Quality**: Production-ready, actionable insights

#### 5. **Premium Report Viewer** (`apps/web/src/pages/Report.tsx`)
- **Design**: "Bloomberg Terminal meets The Economist"
- Typography: Crimson Pro (serif) + IBM Plex Sans
- Color palette: Deep charcoal + warm cream + financial blue/gold
- Features:
  - Executive summary with TL;DR
  - 5 article cards with images
  - Expandable full analysis
  - Share/email actions
  - Mobile responsive

#### 6. **API Integration** (`apps/web/src/lib/api.ts`)
- Company detection endpoint
- Report generation endpoint
- Proper error handling
- TypeScript interfaces

#### 7. **Database Schema** (`packages/database/prisma/schema.prisma`)
- Complete schema ready (not yet used in app)
- Models: User, ReportConfig, GeneratedReport, ArticleFeedback, ReportRecipient

#### 8. **End-to-End Integration**
- Onboarding â†’ Real API call â†’ Report generation â†’ Premium viewer
- Data flows via React Router state
- Error handling throughout

### âŒ Not Yet Built

1. **Report Storage** - Reports aren't saved to database yet
2. **Background Jobs** - No BullMQ/async processing
3. **User Authentication** - Signup flow incomplete
4. **Viral Sharing** - No public report links
5. **Feedback System** - Can't rate articles yet
6. **Dashboard** - No report management UI
7. **Email Delivery** - No Resend integration
8. **Deployment** - Not on GCP yet

---

## Getting Started

### Prerequisites
```bash
# Required
- Node.js 18+ (project uses v24.7.0)
- pnpm (v10.12.4)
- PostgreSQL database (Neon recommended)

# API Keys Required
- ANTHROPIC_API_KEY (Claude Sonnet 4.5)
- OPENAI_API_KEY (gpt-image-1)
- TAVILY_API_KEY (web search)
- GOOGLE_AI_API_KEY (Gemini Flash - logo extraction)
```

### Installation

```bash
# 1. Clone and install
cd /path/to/clippingai
pnpm install

# 2. Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# 3. Set up database
cd packages/database
pnpm prisma generate
pnpm prisma migrate dev

# 4. Start development servers (from root)
# Terminal 1: API
pnpm --filter @clippingai/api dev

# Terminal 2: Web (on port 5173!)
VITE_PORT=5173 pnpm --filter @clippingai/web dev
```

### Verify Setup
1. API: http://localhost:3001/health (should return `{"status":"ok"}`)
2. Web: http://localhost:5173 (should show landing page)

---

## Architecture

### Monorepo Structure
```
clippingai/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/              # Express backend
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts              # Server entry
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ onboarding.ts    # Company detection endpoints
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ reports.ts       # Report generation endpoint
â”‚   â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚   â”‚       â”œâ”€â”€ companyDetection.ts   # Company + logo detection
â”‚   â”‚   â”‚       â””â”€â”€ reportGeneration.ts   # 7-step AI pipeline â­
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â””â”€â”€ web/              # React frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ pages/
â”‚       â”‚   â”‚   â”œâ”€â”€ Landing.tsx       # Email capture
â”‚       â”‚   â”‚   â”œâ”€â”€ Onboarding.tsx    # 9-step flow
â”‚       â”‚   â”‚   â””â”€â”€ Report.tsx        # Premium viewer â­
â”‚       â”‚   â”œâ”€â”€ styles/
â”‚       â”‚   â”‚   â”œâ”€â”€ landing.css
â”‚       â”‚   â”‚   â”œâ”€â”€ onboarding.css
â”‚       â”‚   â”‚   â””â”€â”€ report.css        # Editorial styling â­
â”‚       â”‚   â””â”€â”€ lib/
â”‚       â”‚       â””â”€â”€ api.ts            # API client
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ database/         # Prisma + schema
â”‚   â”‚   â”œâ”€â”€ prisma/
â”‚   â”‚   â”‚   â””â”€â”€ schema.prisma         # Complete schema â­
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â””â”€â”€ shared/           # Shared types
â”‚       â””â”€â”€ index.ts
â”œâ”€â”€ .env                  # Environment variables (not in git)
â”œâ”€â”€ .env.example          # Template
â”œâ”€â”€ package.json          # Root workspace config
â””â”€â”€ pnpm-workspace.yaml
```

### Data Flow

```
User Journey:
1. Landing â†’ Enter email
2. POST /api/onboarding/detect-company
   â†“ Company detection (scraping + Gemini Flash)
3. Onboarding â†’ Verify company â†’ Select reports
4. POST /api/reports/generate
   â†“ 7-step AI pipeline (~2 min)
   â”œâ”€ Claude: Query planning
   â”œâ”€ Tavily: Web search
   â”œâ”€ Claude: Article extraction
   â”œâ”€ Claude: Summarization
   â”œâ”€ Claude: Synthesis
   â”œâ”€ OpenAI: Image generation
   â””â”€ Return: GeneratedReport JSON
5. Navigate to /report with state
6. Display premium report viewer
7. CTA â†’ Continue to questions/signup
```

### AI Pipeline Details

**File**: `apps/api/src/services/reportGeneration.ts`

```typescript
export async function generateReport(input: ReportGenerationInput) {
  // Step 1: Claude generates 5-7 optimal search queries
  const queries = await planSearchQueries(input);

  // Step 2: Tavily executes searches (5 results per query)
  const searchResults = await executeSearches(queries);

  // Step 3: Claude ranks and selects top 5 articles
  const selectedArticles = await extractAndRankArticles(searchResults, input, 5);

  // Step 4: Claude creates 300-500 word analysis for each
  const summarizedArticles = await summarizeArticles(selectedArticles, input);

  // Step 5: Claude synthesizes overall TL;DR
  const tldr = await synthesizeReport(summarizedArticles, input);

  // Step 6: OpenAI generates professional images
  await generateArticleImages(summarizedArticles);

  return { summary: tldr, articles: summarizedArticles, metadata };
}
```

**Key Points**:
- Modular design - each step is independent
- Observable - console logging throughout
- Testable - easy to mock each step
- Extensible - add steps without breaking existing flow

---

## Key Files & Directories

### Must-Understand Files

| File | Purpose | Notes |
|------|---------|-------|
| `apps/api/src/services/reportGeneration.ts` | **Core product logic** - 7-step AI pipeline | 428 lines, well-commented |
| `apps/web/src/pages/Report.tsx` | Premium report viewer | Editorial design, 340 lines |
| `apps/web/src/styles/report.css` | Report styling | Crimson Pro + IBM Plex Sans |
| `packages/database/prisma/schema.prisma` | Database schema | Ready but not integrated |
| `apps/api/src/services/companyDetection.ts` | Company + logo detection | Uses Gemini Flash |
| `apps/web/src/pages/Onboarding.tsx` | 9-step onboarding flow | Real API integration |
| `apps/web/src/lib/api.ts` | Frontend API client | All backend calls |

### Configuration Files

| File | Purpose |
|------|---------|
| `.env` | Environment variables (NEVER commit!) |
| `.env.example` | Template for required variables |
| `pnpm-workspace.yaml` | Monorepo workspace config |
| `tsconfig.json` | TypeScript root config |
| `packages/database/prisma/schema.prisma` | Database schema |

---

## Environment Variables

### Required for Core Functionality

```bash
# API Keys (REQUIRED for generation)
ANTHROPIC_API_KEY="sk-ant-..."        # Claude Sonnet 4.5
OPENAI_API_KEY="sk-..."               # gpt-image-1
TAVILY_API_KEY="tvly-dev-..."         # Web search
GOOGLE_AI_API_KEY="AIza..."           # Gemini Flash (logo extraction)

# Database (REQUIRED but not yet used)
DATABASE_URL="postgresql://user:pass@host:5432/clippingai?sslmode=require"

# Optional (can work without)
REDIS_URL="redis://localhost:6379"   # Not used yet
RESEND_API_KEY="re_..."               # Not used yet
JWT_SECRET="your-secret"              # Not used yet

# App Config
VITE_API_URL="http://localhost:3001" # Frontend â†’ Backend
API_PORT="3001"                       # Backend port
FRONTEND_URL="http://localhost:5173" # Backend â†’ Frontend (CORS)
NODE_ENV="development"
```

### Getting API Keys

1. **Anthropic (Claude)**: https://console.anthropic.com/
   - Model: `claude-sonnet-4-5-20250929`
   - Cost: ~$0.03 per report generation

2. **OpenAI (Images)**: https://platform.openai.com/
   - Model: `gpt-image-1`
   - Cost: $0.02-$0.19 per image (5 images per report)

3. **Tavily (Search)**: https://tavily.com/
   - Free tier: 1000 searches/month
   - ~7 searches per report

4. **Google AI (Gemini)**: https://makersuite.google.com/
   - Model: `gemini-1.5-flash`
   - Used only for logo extraction

5. **Neon (Database)**: https://neon.tech/
   - Free tier includes PostgreSQL
   - Just copy connection string

---

## Testing the Product

### End-to-End Test Flow

```bash
# 1. Ensure both servers are running
# Terminal 1:
pnpm --filter @clippingai/api dev

# Terminal 2:
VITE_PORT=5173 pnpm --filter @clippingai/web dev

# 2. Open browser
open http://localhost:5173

# 3. Test with real company emails
test@anthropic.com
test@stripe.com
test@vercel.com

# 4. Expected flow:
# - Landing page â†’ Enter email
# - Company detection (~2-3 sec)
# - Verify company info
# - Select "Competitor Intelligence"
# - Click "Generate Report"
# - Wait ~2 minutes (watch API logs!)
# - View stunning report with real data
```

### Testing Individual Components

```bash
# Test API health
curl http://localhost:3001/health

# Test company detection
curl -X POST http://localhost:3001/api/onboarding/detect-company \
  -H "Content-Type: application/json" \
  -d '{"email":"test@anthropic.com"}'

# Test report generation (takes ~2 min!)
curl -X POST http://localhost:3001/api/reports/generate \
  -H "Content-Type: application/json" \
  -d '{
    "companyName": "Anthropic",
    "companyDomain": "anthropic.com",
    "industry": "AI",
    "competitors": ["OpenAI"],
    "reportType": "competitor_landscape",
    "dateRange": 7
  }'
```

### What to Look For

**âœ… Success Indicators**:
- Company logo appears correctly
- Report generates without errors
- All 5 articles have images
- Articles are relevant and insightful
- Report layout is beautiful
- No console errors

**âŒ Common Issues**:
- Missing API keys â†’ Check `.env`
- Port conflicts â†’ Kill old processes: `lsof -ti:3001 | xargs kill -9`
- Slow generation â†’ Normal! Takes ~2 min
- Missing images â†’ Check OPENAI_API_KEY
- Generic company info â†’ API key might be invalid

---

## What's Next

### Immediate Priorities (To Make Product Production-Ready)

#### 1. **Report Storage** (High Priority)
**Why**: Reports currently live in memory only
**What to do**:
- Wire up Prisma to save `GeneratedReport` to database
- Update `POST /api/reports/generate` to save before returning
- Add `GET /api/reports/:id` endpoint
- Store user context with reports

**Files to modify**:
- `apps/api/src/routes/reports.ts`
- Create new `apps/api/src/services/reportStorage.ts`

**Estimated time**: 2-3 hours

#### 2. **User Authentication** (High Priority)
**Why**: Signup flow exists but doesn't create accounts
**What to do**:
- Implement JWT-based auth
- Create `POST /api/auth/signup` endpoint
- Create `POST /api/auth/login` endpoint
- Add auth middleware to protected routes
- Store user in database

**Files to create/modify**:
- Create `apps/api/src/services/auth.ts`
- Create `apps/api/src/routes/auth.ts`
- Create `apps/api/src/middleware/auth.ts`
- Update `apps/web/src/pages/Onboarding.tsx` signup handler

**Estimated time**: 4-6 hours

#### 3. **Background Jobs** (Medium Priority)
**Why**: Report generation blocks for 2 minutes
**What to do**:
- Install BullMQ + Redis
- Move report generation to background job
- Return job ID immediately
- Poll for completion or use websockets
- Update UI to show progress

**Files to create/modify**:
- Create `apps/api/src/services/jobQueue.ts`
- Create `apps/api/src/jobs/reportGeneration.ts`
- Update `apps/api/src/routes/reports.ts`
- Update `apps/web/src/pages/Onboarding.tsx`

**Estimated time**: 6-8 hours

#### 4. **Viral Sharing** (Medium Priority)
**Why**: Growth mechanism - let users share reports
**What to do**:
- Generate unique public URLs (`/r/:publicSlug`)
- Add share buttons (Twitter, LinkedIn, email)
- Track views and conversions
- Add "Create Your Own" CTA on shared reports

**Files to create/modify**:
- Create `apps/web/src/pages/PublicReport.tsx`
- Update `apps/api/src/routes/reports.ts`
- Update `apps/web/src/pages/Report.tsx` (share button)

**Estimated time**: 3-4 hours

### Future Enhancements

5. **Email Delivery** (Resend integration for weekly reports)
6. **Dashboard** (Manage multiple reports, settings)
7. **Article Feedback** (Like/dislike, improve over time)
8. **Multiple Report Types** (Currently only competitor_landscape tested)
9. **Scheduled Reports** (Daily/weekly automation)
10. **Team Features** (Share with colleagues)
11. **Export** (PDF, email)
12. **Analytics** (Track opens, clicks, engagement)

---

## Known Issues & Considerations

### Current Limitations

1. **No Persistence**
   - Reports are not saved to database
   - Refresh = lose report
   - **Fix**: Implement report storage (#1 priority)

2. **Synchronous Generation**
   - Blocks for ~2 minutes
   - Can timeout on slow connections
   - **Fix**: Move to background jobs

3. **No Authentication**
   - Signup flow incomplete
   - Can't associate reports with users
   - **Fix**: Implement JWT auth

4. **Image URLs Expire**
   - OpenAI images are temporary (1 hour)
   - Need to save to permanent storage
   - **Fix**: Upload to GCS/S3, store permanent URLs

5. **Single Report Type Tested**
   - Only `competitor_landscape` fully tested
   - `market_landscape` and `media_monitoring` need testing
   - **Fix**: Test and refine prompts for other types

### Technical Debt

1. **Error Handling**
   - Some endpoints need better error messages
   - Add retry logic for AI API failures

2. **Loading States**
   - Report generation shows progress but could be better
   - Add websockets for real-time updates

3. **Mobile Optimization**
   - Report viewer is responsive but could be better on mobile
   - Test on actual devices

4. **Performance**
   - No caching of search results
   - Could add Redis caching layer

### Security Considerations

1. **API Keys in Code**
   - Never commit `.env` file
   - Use environment variables everywhere
   - Rotate keys regularly

2. **Rate Limiting**
   - No rate limiting on report generation
   - Could be expensive if abused
   - **Add**: Express rate limiter

3. **Input Validation**
   - Using Zod for validation âœ…
   - Make sure all inputs are sanitized

4. **CORS**
   - Currently allows all origins in dev
   - **Fix**: Restrict in production

---

## Common Commands

### Development

```bash
# Start everything (from root)
pnpm dev                              # Both API + Web

# Start individually
pnpm --filter @clippingai/api dev    # API only
pnpm --filter @clippingai/web dev    # Web only
VITE_PORT=5173 pnpm --filter @clippingai/web dev  # Web on specific port

# Database
cd packages/database
pnpm prisma generate                  # Generate Prisma client
pnpm prisma migrate dev               # Run migrations
pnpm prisma studio                    # Open database GUI

# Install packages
pnpm add [package]                    # Install in root
pnpm add [package] --filter @clippingai/api   # Install in API
pnpm add [package] --filter @clippingai/web   # Install in Web

# Type checking
pnpm --filter @clippingai/api tsc --noEmit
pnpm --filter @clippingai/web tsc --noEmit
```

### Debugging

```bash
# Check running processes
lsof -ti:3001                         # Check API port
lsof -ti:5173                         # Check Web port

# Kill processes
lsof -ti:3001 | xargs kill -9         # Kill API
lsof -ti:5173 | xargs kill -9         # Kill Web

# View logs
# API logs show in terminal (console.log)
# Web logs show in browser console

# Test API endpoints
curl -X POST http://localhost:3001/api/reports/generate \
  -H "Content-Type: application/json" \
  -d @test-payload.json
```

### Git

```bash
# Current branch
git branch                            # Should be on 'main'

# Recent commits
git log --oneline -10                 # Last 10 commits

# Commit message format (used in project)
git commit -m "feat: Add new feature"
git commit -m "fix: Fix bug"
git commit -m "chore: Update dependencies"

# View changes
git status
git diff
```

---

## Contact & Resources

### Documentation
- **This file**: `HANDOVER.md`
- **API docs**: None yet (TODO: Add OpenAPI/Swagger)
- **Database schema**: `packages/database/prisma/schema.prisma`

### Key Resources
- Anthropic Claude: https://docs.anthropic.com/
- OpenAI gpt-image-1: https://platform.openai.com/docs/guides/images
- Tavily API: https://docs.tavily.com/
- Prisma: https://www.prisma.io/docs
- Neon: https://neon.tech/docs

### Project Stats
- **Total Files**: ~50+ source files
- **Lines of Code**: ~5,000+ (excluding node_modules)
- **Dependencies**: 40+ packages
- **Database Tables**: 6 models (User, ReportConfig, GeneratedReport, ArticleFeedback, ReportRecipient, ReportView)

### Development Timeline
- **Phase 1**: Landing + Onboarding (âœ… Complete)
- **Phase 2**: Report Generation Pipeline (âœ… Complete)
- **Phase 3**: Premium Report Viewer (âœ… Complete)
- **Phase 4**: End-to-End Integration (âœ… Complete)
- **Phase 5**: Storage + Auth (â³ Next)
- **Phase 6**: Growth Features (ğŸ“‹ Planned)
- **Phase 7**: Scale + Deploy (ğŸ“‹ Planned)

---

## Quick Start Checklist

For the next developer:

- [ ] Clone repo
- [ ] Run `pnpm install`
- [ ] Copy `.env.example` to `.env`
- [ ] Add all API keys to `.env`
- [ ] Run `cd packages/database && pnpm prisma generate`
- [ ] Start API: `pnpm --filter @clippingai/api dev`
- [ ] Start Web: `VITE_PORT=5173 pnpm --filter @clippingai/web dev`
- [ ] Test at http://localhost:5173
- [ ] Generate a real report (use test@anthropic.com)
- [ ] Review this document thoroughly
- [ ] Check git history (`git log --oneline`)
- [ ] Review recent commits for context
- [ ] Read `apps/api/src/services/reportGeneration.ts` (core logic)
- [ ] Read `packages/database/prisma/schema.prisma` (data model)
- [ ] Start with Priority #1: Report Storage

---

## Final Notes

This project has a **solid foundation**. The core product works end-to-end with real AI and produces genuinely valuable reports. The design is distinctive and professional. The code is clean, well-organized, and ready to scale.

**What makes this special**:
1. **Show value first** - Users see the full report before signing up
2. **Real AI** - Not fake data, actual competitive intelligence
3. **Premium experience** - Editorial quality that feels expensive
4. **7-step pipeline** - Sophisticated, modular, extensible

**Next developer's job**:
1. Add persistence (storage)
2. Add authentication
3. Make it async (background jobs)
4. Enable sharing (growth)
5. Deploy and iterate based on user feedback

The hardest parts are done. Now it's about execution and growth! ğŸš€

Good luck! ğŸ’ª
